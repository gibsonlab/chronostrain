{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a07fb2ef7d1774e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Database pipeline for quantification of E.faecalis from metagenomic data\n",
    "\n",
    "## What's in this notebook?\n",
    "\n",
    "This notebook is a modification of `efaecalis.ipynb` to specifically use the following collection of isolates as a reference database:\n",
    "1. The ~2000 isolates from European samples of _E.faecalis_\n",
    "2. The ~350 E. faecalis isolates from the ELMC infant analysis (https://www.nature.com/articles/s41467-022-35178-5)\n",
    "3. All other complete chromosomal assemblies from the Enterococcaceae family outside of _E. faecalis_.\n",
    "\n",
    "*Note: This notebook is specifically meant for running the `infant-nt` dataset analysis and thus we also include isolates from that study.*\n",
    "\n",
    "## Main Prerequisites\n",
    "\n",
    "We require the pre-downloaded collection of ~2000 isolates, archived a TSV file specified by path specified by `EUROPEAN_ISOLATE_INDEX`.\n",
    "We recommend spot-checking the isolates' fastQ files before archiving them into this index (e.g. using Kraken), and ensure that they truly are E. faecalis.\n",
    "\n",
    "This notebook also requires the index of infant isolates, downloaded using the script `infant_nt/download_assemblies.sh`.\n",
    "\n",
    "(Minor note: Note that we allow wildcards in the index file. For instance, you can split the contig multi-fasta into many files and specify a glob search; e.g. `<infant_id>/*.fasta`)\n",
    "\n",
    "All indices above must be a TSV file, with columns ((*) is required):\n",
    "1. Genus*\n",
    "2. Species*\n",
    "3. Strain name* (wrap with quotes if you must include whitespace)\n",
    "4. Accession* (a holdover from \"NCBI Accession\", but it is really just an ID column that just needs to be unique per row.)\n",
    "5. Assembly (For now, a metadata-only column, thus it is optional)\n",
    "6. SeqPath*\n",
    "7. ChromosomeLen (The length of the chromosome of this isolate/organism, or a best guess. This is metadata; convenient for post-hoc analyses for converting into sample-overall relabund.)\n",
    "8. GFF (Metadata, pointing to the location of the corresponding annotation, if one exists)\n",
    "   \n",
    "The column ordering is not strict -- but the column header names ARE. We use pandas `pd.read_csv` to read in a DataFrame which uses the column header.\n",
    "\n",
    "## Other prerequisites\n",
    "\n",
    "Other than that, the standard prereqs apply:\n",
    "We recommend using a `conda` environment for this notebook, with `ipywidgets` installed and updated. None of the operations of this notebook requires a GPU.\n",
    "This notebook requires that the following software is installed.\n",
    "- chronostrain (python>=3.10, the basic recipe `conda_basic.yml` or the full recipe `conda_full.yml`)\n",
    "- primersearch (http://emboss.open-bio.org/, https://anaconda.org/bioconda/emboss)\n",
    "- dashing2 (2023 Baker and Langmead: https://github.com/dnbaker/dashing2)\n",
    "\n",
    "### Hardware requirements\n",
    " \n",
    "None of the operations of this notebook requires a GPU. \n",
    "As of Aug 2023, we estimate that the contents of this notebook requires ~20 GB of hard disk space. \n",
    "At the time that we ran this pipeline, the catalog of non-isolate chromosomal assemblies totalled 14.3 GB, and isolates totalled 1.1GB.\n",
    "Other files (such as the BLAST database, marker seeds and chronostrain-specific byproducts) totalled 5.4 GB, with a peak of ~28 GB when accounting for temporary files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246f795-a67f-4524-8b24-b9962e04a908",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## File paths and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a7a4e2f-7823-4e2a-b046-bbd897a65e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T13:57:12.606748999Z",
     "start_time": "2023-09-28T13:57:12.432061566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/cctm/youn/infant_nt/ref_genomes/index.tsv\n",
      "/data/cctm/youn/infant_nt/ref_genomes/enterococcaceae_index.tsv\n",
      "/home/youn/work/chronostrain/examples/database\n",
      "env: JAX_PLATFORM_NAME=cpu\n",
      "env: TARGET_TAXA=$TARGET_TAXA\n",
      "env: NCBI_REFSEQ_DIR=$NCBI_REFSEQ_DIR\n",
      "env: REFSEQ_INDEX=/data/cctm/youn/infant_nt/ref_genomes/enterococcaceae_index.tsv\n",
      "env: PATH=/usr/bin:/home/youn/mambaforge/envs/chronostrain2/bin:/home/youn/work/bin\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import *\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "\"\"\" ============================================ EDIT THESE SETTINGS BASED ON USER'S CHOICE. ============================================ \"\"\"\n",
    "\"\"\" RefSeq catalog settings\"\"\"\n",
    "TARGET_DIR = Path(\"/data/cctm/youn/infant_nt/database\")  # the base directory for everything else.\n",
    "\n",
    "# ========== for infant catalog. The infant index <INFANT_ISOLATE_INDEX> will be created using the infants <infant_id>/isolate_asemblies/metadata.tsv\n",
    "INFANT_CATALOG_DIR = Path(\"/data/cctm/youn/infant_nt\")\n",
    "INFANT_ISOLATE_INDEX = TARGET_DIR / 'infant_isolates' / 'index.tsv'\n",
    "# ========== European isolate catalog of E. faecalis\n",
    "EUROPEAN_ISOLATE_INDEX = Path(\"/data/local/europe_efaecalis/index.tsv\")\n",
    "# ========== RefSeq index of Enterococcaceae (see efaecalis.ipynb. Download the index of chromosomal assemblies, then take the subset of all non-efaecalis genomes.)\n",
    "REFSEQ_INDEX = Path(\"/data/cctm/youn/infant_nt/ref_genomes/index.tsv\")\n",
    "# filter out E.faecalis entries; we only want to use the isolates.\n",
    "refseq_index_df = pd.read_csv(REFSEQ_INDEX, sep='\\t')\n",
    "refseq_index_df = refseq_index_df.loc[~((refseq_index_df['Genus'] == 'Enterococcus') & (refseq_index_df['Species'] == 'faecalis'))]\n",
    "print(REFSEQ_INDEX)\n",
    "REFSEQ_INDEX = REFSEQ_INDEX.parent / \"enterococcaceae_index.tsv\"\n",
    "print(REFSEQ_INDEX)\n",
    "refseq_index_df.to_csv(REFSEQ_INDEX, sep='\\t', index=False)\n",
    "\n",
    "\"\"\" PGAP ANNOTATION LOCATION \"\"\"  # Refer to the cell which talks about pgap annotations on isolates\n",
    "ISOLATE_PGAP_ANNOTATION_DIR=Path(\"/data/cctm/youn/infant_nt/isolate_pgap_annotations\")\n",
    "\n",
    "\"\"\" RefSeq BLAST database \"\"\"\n",
    "BLAST_DB_DIR = TARGET_DIR / \"blast_db\"\n",
    "BLAST_DB_NAME = \"Efcs_Europe_ELMC\"  # Blast DB to create.\n",
    "\n",
    "\"\"\" Marker seeds \"\"\"\n",
    "MARKER_SEED_DIR = TARGET_DIR / \"marker_seeds\"\n",
    "MARKER_SEED_INDEX = MARKER_SEED_DIR / \"marker_seed_index.tsv\"\n",
    "\n",
    "\"\"\" chronostrain-specific settings \"\"\"\n",
    "NUM_CORES = 8  # number of cores to use (e.g. for blastn)\n",
    "MIN_PCT_IDTY = 75  # accept BLAST hits as markers above this threshold.\n",
    "CHRONOSTRAIN_DB_DIR = TARGET_DIR / \"chronostrain_files\"  # The directory to use for chronostrain's database files.\n",
    "CHRONOSTRAIN_TARGET_JSON = CHRONOSTRAIN_DB_DIR / \"efaecalis.json\"  # the desired final product.\n",
    "CHRONOSTRAIN_TARGET_CLUSTERS = CHRONOSTRAIN_DB_DIR / \"efaecalis.clusters.txt\"  # the clustering file.\n",
    "CHRONOSTRAIN_TARGET_CLUSTERS_99_99PCT = CHRONOSTRAIN_DB_DIR / \"efaecalis.clusters_99_99pct.txt\"  # Alternative clustering file at higher granularity\n",
    "DASHING2_DIR = Path(\"/home/youn/work/bin\")  # Directory that contains the dashing2 executable.\n",
    "\n",
    "\n",
    "\"\"\" ============================================ DO NOT EDIT BELOW ============================================ \"\"\"\n",
    "\"\"\" environment variable extraction \"\"\"\n",
    "try:\n",
    "    VARS_SET\n",
    "except NameError:\n",
    "    VARS_SET = True\n",
    "    _cwd = %pwd\n",
    "    _DB_HELPER_DIR = Path(_cwd).parent.parent / 'database'\n",
    "    _start_path = %env PATH\n",
    "\n",
    "# Work in database example directory, where all the helper scripts and settings.sh are.\n",
    "%cd \"$_DB_HELPER_DIR\"\n",
    "# Don't use GPU when importing jaxlib through chronostrain.\n",
    "%env JAX_PLATFORM_NAME=cpu  \n",
    "%env TARGET_TAXA=$TARGET_TAXA\n",
    "%env NCBI_REFSEQ_DIR=$NCBI_REFSEQ_DIR\n",
    "%env REFSEQ_INDEX=$REFSEQ_INDEX\n",
    "# Need basic executables, such as \"which\" and \"basename\" (required by primersearch)\n",
    "%env PATH=/usr/bin:$_start_path:$DASHING2_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9ac0c8-1267-4d81-a72d-43384889c37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking EMBOSS primersearch.\n",
      "EMBOSS:6.6.0.0\n",
      "\n",
      "checking dashing2.\n",
      "#Calling Dashing2 version v2.1.19 with command '/home/youn/work/chronostrain/examples/database/dashing2 --version'\n",
      "dashing2 has several subcommands: sketch, cmp, wsketch, and contain.\n",
      "Usage can be seen in those subcommands. (e.g., `dashing2 sketch -h`)\n",
      "\n",
      "\tsketch: converts FastX into k-mer sets/sketches, and sketches BigWig and BED files; also contains functionality from cmp, for one-step sketch and comparisons\n",
      "This is probably the most common subcommand to use.\n",
      "\n",
      "\tcmp: compares previously sketched/decomposed k-mer sets and emits results. alias: dist\n",
      "\n",
      "\tcontain: Takes a k-mer database (built with dashing2 sketch --save-kmers), then computes coverage for all k-mer references using input streams.\n",
      "\twsketch: Takes a tuple of [1-3] input binary files [(u32 or u64), (float or double), (u32 or u64)] and performs weighted minhash sketching.\n",
      "Three files are treated as Compressed Sparse Row (CSR)-format, where the third file contains indptr values, specifying the lengths of consecutive runs of pairs in the first two files corresponding to each row.\n",
      "wsketch is for sketching binary files which have already been summed, whereas sketch is for parsing and sketching (from Fast{qa}, BED, BigWig)\n",
      "\n",
      "\n",
      "Miscellania:\n",
      "printmin: Emit minimizer sequence sets in human-readable form.\n",
      "\n",
      "checking pgap.\n",
      "env: ‘/data/local/pgap/pgap.py’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# === Ensure that these commands work.\n",
    "print(\"checking EMBOSS primersearch.\")\n",
    "!primersearch --version\n",
    "\n",
    "print(\"\\nchecking dashing2.\")\n",
    "!dashing2 --version\n",
    "\n",
    "print(\"\\nchecking pgap.\")\n",
    "!pgap --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda6630-d7c5-4bd7-ac66-e5d1fc8dbed8",
   "metadata": {},
   "source": [
    "## Recipe starts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f279e6f-8d09-4f7e-86f2-6d4e5eb0b478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made /data/cctm/youn/infant_nt/database\n",
      "made /data/cctm/youn/infant_nt/database/blast_db\n",
      "made /data/cctm/youn/infant_nt/database/marker_seeds\n"
     ]
    }
   ],
   "source": [
    "# Prepare directories.\n",
    "TARGET_DIR.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"made {TARGET_DIR}\")\n",
    "BLAST_DB_DIR.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"made {BLAST_DB_DIR}\")\n",
    "MARKER_SEED_DIR.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"made {MARKER_SEED_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3c0d8-296f-44f6-9f3e-c905f52d1adc",
   "metadata": {},
   "source": [
    "### Step 1 - include isolate assemblies\n",
    "\n",
    "Include infant isolates to the database catalog.\n",
    "\n",
    "*Note: This cell does nothing if `infant_nt/download_assemblies.sh` has not been run. It can be safely skipped if one does not want to include these isolates.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "472b5cdf-dae7-4d30-90e5-feb9a1e0d436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found metadata in dir /data/cctm/youn/infant_nt/A00021_T1/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00021_T2/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00106_T1/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00106_T2/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00203_T1/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00203_T2/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02223_T1/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02223_T2/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00031/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00043/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00067/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00185/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00190/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00219/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00502/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00559/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00576/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00908_T1/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00947/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A00995/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01011/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01057/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01077/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01082/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01105/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01107/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01166/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01173/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01176/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01301/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01311/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01506/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01563/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01580/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01583/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01586/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01639/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01653/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01671/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01676/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01678/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01687/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01739/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01802/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01805/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01862/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01866/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01921/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01939/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A01966/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A02053/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A02110/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A02133/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A02138/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A02819/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/A02913/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00002/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00010/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00012/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00013/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00016/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00020/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00027/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00036/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00046/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00053/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00071/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00076/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00085/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00088/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00090/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00092/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00096/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00097/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00100/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00101/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00111/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00116/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00119/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00129/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00136/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00139/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00157_T3/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00174/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00176/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00178/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00235/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00236/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00252/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00268/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00272/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00507/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00518/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00537/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00550/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00553/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00562_T2/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00917/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B00922/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01021/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01042/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01089/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01196/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01236/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01261/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01278/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01339/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01365/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01375/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01471/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01572/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01610/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01616/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01712/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01716/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01719/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01772/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01775/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01797/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B01956/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02005/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02118/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02156/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02211/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02215/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02216/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02255/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02257/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02258/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02263/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02270/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02273/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02315/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02326/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02588/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02720/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/B02722/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01008_T2/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01010/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01012/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01052/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01075/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01201/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01329/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01331/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01387/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01389/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01392/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01443/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01488/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01529/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01530/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01560/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01689/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01695/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01700/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01751/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01752/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01757/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01758/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01832/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01837/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01839/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01841/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01844/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01871/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01877/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01913/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01917/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01919/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01929/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01930/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C01990/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02016/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02047/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02059/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02062/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02097/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02180/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02186/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02236/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02295/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02391/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02565/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02566/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02571/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02695/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02756/isolate_assemblies.\n",
      "Found metadata in dir /data/cctm/youn/infant_nt/C02892/isolate_assemblies.\n"
     ]
    }
   ],
   "source": [
    "# this file points to the output of infant_nt/download_assembly_catalog.sh.\n",
    "from Bio import SeqIO\n",
    "\n",
    "INFANT_ISOLATE_INDEX.parent.mkdir(exist_ok=True, parents=True)\n",
    "infant_isolate_df_entries = []\n",
    "for f in INFANT_CATALOG_DIR.glob(\"*/isolate_assemblies/metadata.tsv\"):\n",
    "    print(\"Found metadata in dir {}.\".format(f.parent))\n",
    "\n",
    "    # =============== Create a dataframe.\n",
    "    df_dir = f.parent\n",
    "    isolate_df = pd.read_csv(f, sep='\\t')\n",
    "    for _, row in isolate_df.iterrows():\n",
    "        # Parse entries.\n",
    "        infant_id = row['Participant']\n",
    "        acc = row['Accession']\n",
    "        genus = row['Genus']\n",
    "        species = row['Species']\n",
    "        timepoint = row['Timepoint']\n",
    "        sample_id = row['SampleId']\n",
    "        source_fasta_path = df_dir / Path(row['FastaPath']).name\n",
    "\n",
    "        # Skip if not E. faecalis.\n",
    "        if not (genus == 'Enterococcus' and species == 'faecalis'):\n",
    "            continue\n",
    "\n",
    "        # Extract the records.\n",
    "        records = list(SeqIO.parse(source_fasta_path, format=\"fasta\"))\n",
    "        total_contig_len = sum(len(record.seq) for record in records)\n",
    "\n",
    "        # Do nothing if no records are available.\n",
    "        if len(records) == 0:\n",
    "            continue\n",
    "\n",
    "        # Add to the dataframe.\n",
    "        infant_isolate_df_entries.append(\n",
    "            (genus, species, f'{infant_id}_t:{timepoint}_s:{sample_id}', infant_id, timepoint, acc, acc, str(source_fasta_path), total_contig_len, 'None')\n",
    "        )\n",
    "\n",
    "\n",
    "# Create dataframe and save to file.\n",
    "if len(infant_isolate_df_entries) > 0:\n",
    "    infant_isolate_df = pd.DataFrame(\n",
    "        infant_isolate_df_entries, \n",
    "        columns=['Genus', 'Species', 'Strain', 'Infant', 'T', 'Accession', 'Assembly', 'SeqPath', 'ChromosomeLen', 'GFF']\n",
    "    ).astype(\n",
    "        {\n",
    "            'Genus': 'string',\n",
    "            'Species': 'string',\n",
    "            'Strain': 'string',\n",
    "            'Infant': 'string',\n",
    "            'T': 'string',\n",
    "            'Accession': 'string',\n",
    "            'Assembly': 'string',\n",
    "            'SeqPath': 'string',\n",
    "            'ChromosomeLen': 'int',\n",
    "            'GFF': 'string'\n",
    "        }\n",
    "    )\n",
    "    infant_isolate_df.to_csv(INFANT_ISOLATE_INDEX, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef23e0-cf03-4139-adcd-527b932c0026",
   "metadata": {},
   "source": [
    "### Step 2: Build the marker seed catalog.\n",
    "\n",
    "ChronoStrain only needs a FASTA file of marker seeds (one multi-fasta file per marker gene), and a single TSV file that catalogs them.\n",
    "However, to get there, we need to take a few steps...\n",
    "\n",
    "#### Step 2.1: Download MLST schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "053f68f2-641e-4a38-866e-9ba5b9fcbd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading marker seeds from MLST schema.\n",
      "Targeting 1 taxa using MLST scheme.\n",
      "Fetching URL resource https://pubmlst.org/static/data/dbases.xml\n",
      "Got a response of size 152.35 KB.\n",
      "Schema type id: \n",
      "Handling locus gdh\n",
      "Fetching URL resource https://rest.pubmlst.org/db/pubmlst_efaecalis_seqdef/loci/gdh/alleles_fasta\n",
      "Got a response of size 76.36 KB.\n",
      "Handling locus gyd\n",
      "Fetching URL resource https://rest.pubmlst.org/db/pubmlst_efaecalis_seqdef/loci/gyd/alleles_fasta\n",
      "Got a response of size 23.67 KB.\n",
      "Handling locus pstS\n",
      "Fetching URL resource https://rest.pubmlst.org/db/pubmlst_efaecalis_seqdef/loci/pstS/alleles_fasta\n",
      "Got a response of size 79.37 KB.\n",
      "Handling locus gki\n",
      "Fetching URL resource https://rest.pubmlst.org/db/pubmlst_efaecalis_seqdef/loci/gki/alleles_fasta\n",
      "Got a response of size 57.64 KB.\n",
      "Handling locus aroE\n",
      "Fetching URL resource https://rest.pubmlst.org/db/pubmlst_efaecalis_seqdef/loci/aroE/alleles_fasta\n",
      "Got a response of size 65.53 KB.\n",
      "Handling locus xpt\n",
      "Fetching URL resource https://rest.pubmlst.org/db/pubmlst_efaecalis_seqdef/loci/xpt/alleles_fasta\n",
      "Got a response of size 58.15 KB.\n",
      "Handling locus yqiL\n",
      "Fetching URL resource https://rest.pubmlst.org/db/pubmlst_efaecalis_seqdef/loci/yqiL/alleles_fasta\n",
      "Got a response of size 61.44 KB.\n"
     ]
    }
   ],
   "source": [
    "!python python_helpers/mlst_download.py -t \"Enterococcus faecalis\" -w \"$MARKER_SEED_DIR\"/mlst_schema -o \"$MARKER_SEED_DIR\"/mlst_seeds.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d382c6-2e7a-4579-8a74-22fc1f2e37a3",
   "metadata": {},
   "source": [
    "#### Step 2.2: Non-standard genes\n",
    "\n",
    "Here, we save some work and re-use the marker seeds discovered using PCR primers in the `database` example notebook (efaecalis.ipynb)\n",
    "\n",
    "(The FASTA files representing primer-hits with lengths <150 were left out. We also took the first entry for each fasta file (due to the primer hits' overall similarity) except for fsrB which appears to have quite a bit of variability.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab860e5-fac0-405a-acff-4a7b2aff10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /mnt/e/efaecalis_db/marker_seeds/cbh.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsA.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsB.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsC.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsD.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsE.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsF.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsG.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsH.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsI.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsJ.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cpsK.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cylA.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/cylB.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/esp.fasta \"$MARKER_SEED_DIR\"/\n",
    "!cp /mnt/e/efaecalis_db/marker_seeds/fsrB.fasta \"$MARKER_SEED_DIR\"/\n",
    "\n",
    "with open(MARKER_SEED_DIR / \"virulence_seeds.tsv\", \"wt\") as metadata_tsv:\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cbh\", MARKER_SEED_DIR / \"cbh.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsA\", MARKER_SEED_DIR / \"cpsA.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsB\", MARKER_SEED_DIR / \"cpsB.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsC\", MARKER_SEED_DIR / \"cpsC.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsD\", MARKER_SEED_DIR / \"cpsD.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsE\", MARKER_SEED_DIR / \"cpsE.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsF\", MARKER_SEED_DIR / \"cpsF.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsG\", MARKER_SEED_DIR / \"cpsG.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsH\", MARKER_SEED_DIR / \"cpsH.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsI\", MARKER_SEED_DIR / \"cpsI.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsJ\", MARKER_SEED_DIR / \"cpsJ.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cpsK\", MARKER_SEED_DIR / \"cpsK.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cylA\", MARKER_SEED_DIR / \"cylA.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"cylB\", MARKER_SEED_DIR / \"cylB.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"esp\", MARKER_SEED_DIR / \"esp.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)\n",
    "    print(\"{}\\t{}\\t{}\".format(\"fsrB\", MARKER_SEED_DIR / \"fsrB.fasta\", \"POLYMORPHIC\"), file=metadata_tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175fe89-5795-425b-99e2-82e5ef6bfb33",
   "metadata": {},
   "source": [
    "#### Step 2.3: Annotate isolates.\n",
    "\n",
    "**Note 1: The ELMC isolates are grabbed via the `infant-nt` example (`download_assemblies.sh`)**\n",
    "\n",
    "**Note 2: this step takes a long time; consider assigning the task to a dedicated compute cluster.** Alternatively, grab the pre-computed annotation GFF files from (Todo zenodo record URL)**, and place its contents into <INFANT_ISOLATE_INDEX.parent>, so that it matches the directory pattern `<ISOLATE_PGAP_ANNOTATION_DIR>/ <isolate_acc>`.\n",
    "\n",
    "The cell has been included anyway, with the code commented out to demonstrate how it was done within the context of this notebook.\n",
    "\n",
    "For clarity: The goal here is to run the `pgap` tool (Prokaryotic Genome Annotation Pipeline) from NCBI to annotate the genome of each isolate, via the command\n",
    "`pgap -r -o <INFANT_ISOLATE_INDEX.parent>/annotations/<isolate_acc> -g <isolate_assembly_fasta> -s 'Enterococcus faecalis'`\n",
    "where the fasta file `<isolate_assembly_fasta>` points to a multi-fasta file of the assembled contigs. \n",
    "\n",
    "The only catch is that `pgap` does not handle fasta records with malformed IDs, has a sequence of trailing N's on either ends, nor records with length < 200. Thus N's must be trimmed from each record and records of length < 200 (after trimming) must be removed.\n",
    "([Reference: pgap github wiki](https://github.com/ncbi/pgap/wiki/Input-Files))\n",
    "The isolate FASTA files have plenty of records that violate these rules, so some cleaning must be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5712c60-49be-4271-af67-38afd280b34b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Uncomment the code in this cell to run it within the notebok. This requires NCBI's pgap software.\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "# cwd = Path().resolve()\n",
    "\n",
    "# print(f\"Reading infant isolate catalog from {INFANT_CATALOG_DIR}/*/isolate_assemblies/metadata.tsv\")\n",
    "# for f in INFANT_CATALOG_DIR.glob(\"*/isolate_assemblies/metadata.tsv\"):\n",
    "#     infant_id = f.parent.parent.name\n",
    "#     print(f\"Handling isolates from {infant_id}\")\n",
    "    \n",
    "#     # =============== Create a dataframe.\n",
    "#     isolate_df = pd.read_csv(f, sep='\\t')\n",
    "#     for _, row in isolate_df.iterrows():\n",
    "#         # Parse entries.\n",
    "#         participant = row['Participant']\n",
    "#         acc = row['Accession']\n",
    "#         genus = row['Genus']\n",
    "#         species = row['Species']\n",
    "#         timepoint = row['Timepoint']\n",
    "#         sample_id = row['SampleId']\n",
    "#         source_fasta_path = Path(row['FastaPath'])\n",
    "\n",
    "#         # Skip if not E. faecalis.\n",
    "#         if not (genus == 'Enterococcus' and species == 'faecalis'):\n",
    "#             continue\n",
    "\n",
    "#         # setup\n",
    "#         isolate_out_dir = INFANT_ISOLATE_INDEX.parent / \"annotations\" / acc\n",
    "#         tmp_dir = isolate_out_dir.parent / '_tmp'\n",
    "#         taxa_name = f'{genus} {species}'\n",
    "\n",
    "#         isolate_out_dir.parent.mkdir(exist_ok=True, parents=True)\n",
    "#         tmp_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "#         # reformat fasta file, remove punctuations.\n",
    "#         fixed_fasta_path = tmp_dir / f\"{acc}.fasta\"\n",
    "#         with open(fixed_fasta_path, \"wt\") as f:\n",
    "#             for r_idx, record in enumerate(SeqIO.parse(source_fasta_path, \"fasta\")):\n",
    "#                 seq = record.seq.rstrip('N')\n",
    "#                 if len(seq) < 200:\n",
    "#                     l = len(record.seq)\n",
    "#                     print(f\"Skipping record {record.id} because it has length < 200 (len={l}) (possibly after stripping Ns)\")\n",
    "#                     continue\n",
    "#                 record.id = f\"{acc}:CONTIG_{r_idx}\"\n",
    "#                 record.seq = seq\n",
    "#                 SeqIO.write([record], handle=f, format=\"fasta\")\n",
    "\n",
    "#         # run pgap.\n",
    "#         os.chdir(tmp_dir)\n",
    "#         print(f\"[DIR = {tmp_dir}] pgap -r -o {isolate_out_dir} -g {fixed_fasta_path} -s '{taxa_name}'\")\n",
    "#         !pgap -r -o {isolate_out_dir} -g {fixed_fasta_path} -s '{taxa_name}' --quiet --no-self-update\n",
    "        \n",
    "#         # go back to working dir, and cleanup.\n",
    "#         os.chdir(cwd)\n",
    "#         shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6087367-dfbf-4d16-86ba-3d7117115c42",
   "metadata": {},
   "source": [
    "Next, parse the annotations and grab the genes. The cell below requires the package GFF package (https://github.com/chapmanb/bcbb/tree/master/gff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b751b901-0ec1-41c6-ac39-816f00bef446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805e519c616e48d0bfd25dd04f08d492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/349 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annot.gff not found for GCA_902159085. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902159895. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902159915. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902159945. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902160035. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902165355. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902165265. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902165295. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902165305. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902159845. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902159955. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902160045. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902163595. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902163605. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902165625. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902163975. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902163015. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902163755. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902163855. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902161865. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902164405. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902164385. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902164395. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902166695. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902162265. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902162245. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902162345. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902165335. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902159835. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902159855. Did pgap run correctly?\n",
      "annot.gff not found for GCA_902159885. Did pgap run correctly?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accession</th>\n",
       "      <th>Contig</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Length</th>\n",
       "      <th>PositionLeft</th>\n",
       "      <th>PositionRight</th>\n",
       "      <th>PositiveStrand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCA_902164875</td>\n",
       "      <td>0</td>\n",
       "      <td>rrf</td>\n",
       "      <td>116</td>\n",
       "      <td>94</td>\n",
       "      <td>210</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GCA_902164875</td>\n",
       "      <td>0</td>\n",
       "      <td>bgsA</td>\n",
       "      <td>1005</td>\n",
       "      <td>482</td>\n",
       "      <td>1487</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCA_902164875</td>\n",
       "      <td>0</td>\n",
       "      <td>bgsB</td>\n",
       "      <td>1224</td>\n",
       "      <td>1533</td>\n",
       "      <td>2757</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCA_902164875</td>\n",
       "      <td>0</td>\n",
       "      <td>fabK</td>\n",
       "      <td>957</td>\n",
       "      <td>6278</td>\n",
       "      <td>7235</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCA_902164875</td>\n",
       "      <td>0</td>\n",
       "      <td>fabD</td>\n",
       "      <td>930</td>\n",
       "      <td>7267</td>\n",
       "      <td>8197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218638</th>\n",
       "      <td>GCA_902165805</td>\n",
       "      <td>8</td>\n",
       "      <td>sat4</td>\n",
       "      <td>543</td>\n",
       "      <td>3328</td>\n",
       "      <td>3871</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218639</th>\n",
       "      <td>GCA_902165805</td>\n",
       "      <td>8</td>\n",
       "      <td>aph3IIIa</td>\n",
       "      <td>795</td>\n",
       "      <td>3963</td>\n",
       "      <td>4758</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218640</th>\n",
       "      <td>GCA_902165805</td>\n",
       "      <td>9</td>\n",
       "      <td>cylR2</td>\n",
       "      <td>201</td>\n",
       "      <td>895</td>\n",
       "      <td>1096</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218641</th>\n",
       "      <td>GCA_902165805</td>\n",
       "      <td>9</td>\n",
       "      <td>cylLL</td>\n",
       "      <td>207</td>\n",
       "      <td>1499</td>\n",
       "      <td>1706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218642</th>\n",
       "      <td>GCA_902165805</td>\n",
       "      <td>9</td>\n",
       "      <td>cylLS</td>\n",
       "      <td>192</td>\n",
       "      <td>1739</td>\n",
       "      <td>1931</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218643 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accession  Contig      Gene  Length  PositionLeft  PositionRight  \\\n",
       "0       GCA_902164875       0       rrf     116            94            210   \n",
       "1       GCA_902164875       0      bgsA    1005           482           1487   \n",
       "2       GCA_902164875       0      bgsB    1224          1533           2757   \n",
       "3       GCA_902164875       0      fabK     957          6278           7235   \n",
       "4       GCA_902164875       0      fabD     930          7267           8197   \n",
       "...               ...     ...       ...     ...           ...            ...   \n",
       "218638  GCA_902165805       8      sat4     543          3328           3871   \n",
       "218639  GCA_902165805       8  aph3IIIa     795          3963           4758   \n",
       "218640  GCA_902165805       9     cylR2     201           895           1096   \n",
       "218641  GCA_902165805       9     cylLL     207          1499           1706   \n",
       "218642  GCA_902165805       9     cylLS     192          1739           1931   \n",
       "\n",
       "        PositiveStrand  \n",
       "0                 True  \n",
       "1                 True  \n",
       "2                 True  \n",
       "3                 True  \n",
       "4                 True  \n",
       "...                ...  \n",
       "218638            True  \n",
       "218639            True  \n",
       "218640           False  \n",
       "218641            True  \n",
       "218642            True  \n",
       "\n",
       "[218643 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "from BCBio import GFF\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# ================ Functions for appending gene sequences to fasta records\n",
    "gene_paths = {}\n",
    "def get_gene_path(gene_name):\n",
    "    \"\"\"\n",
    "    Retrieves the gene path from the dist `gene_paths`, but with some pre-cleaning.\n",
    "    \"\"\"\n",
    "    if gene_name in gene_paths:\n",
    "        return gene_paths[gene_name]\n",
    "    else:\n",
    "        p = INFANT_ISOLATE_INDEX.parent / 'genes' / f'{gene_name}.fasta'\n",
    "        if p.exists():\n",
    "            p.unlink()  # clear the contents\n",
    "        else:\n",
    "            p.parent.mkdir(exist_ok=True, parents=True)\n",
    "        gene_paths[gene_name] = p\n",
    "        return p\n",
    "\n",
    "\n",
    "def add_gene_seq(gene_name: str, gene_seq: Seq, gene_id: str, description: str = \"\"):\n",
    "    \"\"\"\n",
    "    Adds a sequence (gene_seq) to a fasta file, where path is derived from get_gene_path.\n",
    "    \"\"\"\n",
    "    gene_path = get_gene_path(gene_name)\n",
    "    # this opens the fasta in \"a\" mode, but get_gene_path clears its contents to ensure that each time this code is run, it's a fresh start.\n",
    "    with open(gene_path, \"a\") as f:  \n",
    "        SeqIO.write(\n",
    "            [SeqRecord(gene_seq, id=gene_id, name=gene_name, description=description)], \n",
    "            handle=f, \n",
    "            format='fasta'\n",
    "        )\n",
    "\n",
    "\n",
    "def remove_punctuations(s: str) -> str:\n",
    "    \"\"\"\n",
    "    To ensure that a gene name can be translated into a POSIX-friendly file path, this function removes punctuations.\n",
    "    \"\"\"\n",
    "    return s.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "\n",
    "# ========================= Process the pgap results, using the above helpers.\n",
    "df_entries = []\n",
    "\n",
    "infant_isolate_df = pd.read_csv(INFANT_ISOLATE_INDEX, sep='\\t')  # load the isolate catalog, which has metadata that we need\n",
    "\n",
    "pbar = tqdm(infant_isolate_df.iterrows(), total=infant_isolate_df.shape[0])\n",
    "for _, row in pbar:\n",
    "    acc = row['Accession']\n",
    "    pbar.set_postfix({\"Isolate\": acc})\n",
    "    annot_subdir = ISOLATE_PGAP_ANNOTATION_DIR / acc\n",
    "    gff_path = annot_subdir / \"annot.gff\"  # annotations file containing gene names and locations\n",
    "    seq_path = annot_subdir / f\"{acc}.fasta\"  # the sequence fasta file to extract genes from\n",
    "    if not gff_path.exists():\n",
    "        print(f\"annot.gff not found for {acc}. Did pgap run correctly?\")\n",
    "        continue\n",
    "\n",
    "    seq_records = {record.id: record.seq for record in SeqIO.parse(seq_path, \"fasta\")}\n",
    "    with open(gff_path, \"rt\") as gff_handle:\n",
    "        for rec in GFF.parse(gff_handle, limit_info=dict(gff_type=['gene'])):\n",
    "            # assume that the record is of the format (<isolate_acc>:CONTIG_<contig_index>), to be handled via the PGAP preprocessing. (see above cell)\n",
    "            contig_idx = int(rec.id.split(\"_\")[-1])\n",
    "            \n",
    "            for feature in rec.features:\n",
    "                # find gene name; exclude putative genes (pgaptmp_*)\n",
    "                gene_names = sorted([remove_punctuations(n) for n in feature.qualifiers['Name'] if not n.startswith('pgaptmp')])\n",
    "                \n",
    "                if len(gene_names) > 0:\n",
    "                    gene_name = gene_names[0]  # if there are multiple candidate names, take the lexicographically first one.\n",
    "                    loc = feature.location\n",
    "                    gene_seq = loc.extract(seq_records[rec.id])\n",
    "\n",
    "                    # Add count to dataframe\n",
    "                    df_entries.append({\n",
    "                        'Accession': acc,\n",
    "                        'Contig': contig_idx,\n",
    "                        'Gene': gene_name,\n",
    "                        'Length': len(gene_seq),\n",
    "                        'PositionLeft': int(loc.start),\n",
    "                        'PositionRight': int(loc.end),\n",
    "                        'PositiveStrand': loc.strand > 0\n",
    "                    })\n",
    "\n",
    "                    # write record to fasta\n",
    "                    gene_id = f\"{acc}:{gene_name}:{contig_idx}\"\n",
    "                    desc = f\"Extracted from {acc} using pgap, position {str(loc)} of contig index {contig_idx}\"\n",
    "                    add_gene_seq(gene_name, gene_seq, gene_id, description=desc)\n",
    "    \n",
    "    del seq_records  # clean up\n",
    "\n",
    "gene_annotations = pd.DataFrame(df_entries)\n",
    "del df_entries  # clean up\n",
    "\n",
    "gene_annotations.to_feather(INFANT_ISOLATE_INDEX.parent / \"genes.feather\")\n",
    "display(gene_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d0f43-0af0-45bb-828c-21f70f95e572",
   "metadata": {},
   "source": [
    "Run multiple alignment. This step requires MAFFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48be6972-0083-4975-855b-2f9f3c658544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfa89e9425f442bae8a1d2b08f8ccc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple Alignment:   0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "gene_annotations = pd.read_feather(INFANT_ISOLATE_INDEX.parent / \"genes.feather\")\n",
    "n_isolate_accs = len(pd.unique(gene_annotations['Accession']))\n",
    "tol_frac = 0.5  # don't align genes found in fewer than this fraction of isolates\n",
    "\n",
    "n_genes = len(pd.unique(gene_annotations['Gene']))\n",
    "pbar = tqdm(gene_annotations.groupby(\"Gene\"), total=n_genes, desc=\"Multiple Alignment\")\n",
    "\n",
    "\n",
    "for gene_name, gene_section in pbar:\n",
    "    pbar.set_postfix({\"Gene\": gene_name})\n",
    "    count = gene_section.shape[0]\n",
    "    if count < tol_frac * n_isolate_accs:\n",
    "        continue\n",
    "    \n",
    "    # run multiple alignment.\n",
    "    gene_path = gene_paths[gene_name]\n",
    "    aln_path = INFANT_ISOLATE_INDEX.parent / 'gene_alignments' / f'{gene_name}.aln.fasta'\n",
    "    if not aln_path.parent.exists():\n",
    "        aln_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "    if not aln_path.exists():\n",
    "        os.system(f\"mafft --nuc --quiet --thread 8 {gene_path} > {aln_path}\")  # \">\" overwrites any previous runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda3fcd7-a024-4509-aed0-53d2861d743e",
   "metadata": {},
   "source": [
    "Parse the alignments. Pick the genes that best separate the isolates that are clustered together using only the ST genes + polymorphism/virulence islands.\n",
    "\n",
    "But in order to do this, let's first construct the database with just MLST + virulence genes, to see how well these split the infant isolates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32563d4a-43e2-4222-9b9b-567646b5e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"$MARKER_SEED_DIR\"/mlst_seeds.tsv > \"$MARKER_SEED_DIR\"/mlst_and_virulence.tsv\n",
    "!cat \"$MARKER_SEED_DIR\"/virulence_seeds.tsv >> \"$MARKER_SEED_DIR\"/mlst_and_virulence.tsv\n",
    "\n",
    "\n",
    "!mkdir -p \"$BLAST_DB_DIR\"\n",
    "!env \\\n",
    "    JAX_PLATFORM_NAME=cpu \\\n",
    "    CHRONOSTRAIN_DB_DIR={CHRONOSTRAIN_DB_DIR} \\\n",
    "    CHRONOSTRAIN_LOG_INI={_cwd}/logging.ini \\\n",
    "    chronostrain -c chronostrain.ini \\\n",
    "        make-db \\\n",
    "        -m \"$MARKER_SEED_DIR\"/mlst_and_virulence.tsv \\\n",
    "        -r $INFANT_ISOLATE_INDEX \\\n",
    "        -b \"infant_isolates_only\" -bd $BLAST_DB_DIR \\\n",
    "        --min-pct-idty $MIN_PCT_IDTY \\\n",
    "        -o \"$CHRONOSTRAIN_DB_DIR\"/mlst_virulence_infant_isol.json \\\n",
    "        --threads $NUM_CORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3519b92-a9e3-40d2-8ef0-770c39c2a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "thresh = 0.998\n",
    "!env \\\n",
    "    JAX_PLATFORM_NAME=cpu \\\n",
    "    CHRONOSTRAIN_DB_DIR=\"$CHRONOSTRAIN_DB_DIR\" \\\n",
    "    CHRONOSTRAIN_LOG_INI={_cwd}/logging.ini \\\n",
    "    chronostrain -c chronostrain.ini \\\n",
    "      cluster-db \\\n",
    "      -i \"$CHRONOSTRAIN_DB_DIR\"/mlst_virulence_infant_isol.json \\\n",
    "      -o \"$CHRONOSTRAIN_DB_DIR\"/mlst_virulence_infant_isol.clusters.txt \\\n",
    "      --ident-threshold {thresh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac6037fc-89eb-4028-b031-b0ec88116e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce7a2ee094847f9aa2f18afa6a1704c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target genes: 66\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "infant_isolate_df = pd.read_csv(INFANT_ISOLATE_INDEX, sep='\\t')  # load the isolate catalog, which has metadata that we need\n",
    "gene_annotations = pd.read_feather(INFANT_ISOLATE_INDEX.parent / \"genes.feather\")  # run this if previous cell already ran in a prior instantiation\n",
    "\n",
    "\n",
    "# a function that will compute the necessary distance matrix.\n",
    "def get_splitting_genes(infant_groupings: Dict[str, List[str]], infant_ordering: Dict[str, int]):\n",
    "    \"\"\"\n",
    "    Uses each gene's distane matrix to determine a collection of genes which \"distinguishes\" them across infants.\n",
    "    Refer to `load_gene_distance_matrix` for the details as to what the terms \"distance\" and \"distinguishes\" mean.\n",
    "    \"\"\"\n",
    "    union_isolates = set()\n",
    "    for _, isolate_list in infant_groupings.items():\n",
    "        union_isolates = union_isolates.union(set(isolate_list))\n",
    "        \n",
    "    gene_subset = gene_annotations.loc[gene_annotations['Accession'].isin(union_isolates)]\n",
    "    gene_names = []\n",
    "    gene_nnzs = []\n",
    "    for gene_name, gene_section in gene_subset.groupby(\"Gene\"):\n",
    "        # isolates_with_gene = set(gene_section['Accession'])\n",
    "        # isolates_without_gene = this_isolates.difference(isolates_with_gene)\n",
    "\n",
    "        try:\n",
    "            d = load_gene_distance_matrix(gene_name, infant_groupings, infant_ordering, union_isolates)  # shape is (n_infants, n_infants)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        d_tril = d[np.tril_indices(n=len(infant_ordering), k=-1)]\n",
    "        frac_nnz = np.sum(d_tril > 0) / len(d_tril)\n",
    "\n",
    "        gene_names.append(gene_name)\n",
    "        gene_nnzs.append(frac_nnz)\n",
    "    ordering = np.argsort(gene_nnzs)[::-1]  # decreasing order\n",
    "\n",
    "    return [\n",
    "        gene_names[k]\n",
    "        for k in ordering[:3]  # top three\n",
    "    ]\n",
    "\n",
    "\n",
    "def load_gene_distance_matrix(gene_name: str, infant_groupings: Dict[str, List[str]], infant_ordering: Dict[str, int], union_isolates: Set[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Uses the previously computed multiple alignments to create a distance matrix between infants.\n",
    "    \n",
    "    For each gene g, a matrix is computed:\n",
    "    d[g](i, j) = min_{x \\in isolates_i, y \\in isolates_j} HAMMING_[gene=g](x, y)\n",
    "\n",
    "    d[g](i, j) > 0 indicates that the gene g \"cuts\"/\"distinguishes\" the isolates of i versus the isolates of j, in the sense that \n",
    "    d[g] is a lower bound on the distance between any isolate of i and any isolate of j.\n",
    "    \"\"\"\n",
    "    aln_path = INFANT_ISOLATE_INDEX.parent / 'gene_alignments' / f'{gene_name}.aln.fasta'\n",
    "    if not aln_path.exists():\n",
    "        raise FileNotFoundError(f\"Multiple alignment for {gene_name} didn't run.\")\n",
    "\n",
    "    # Parse the multiple alignment fasta file.\n",
    "    try:\n",
    "        l_aln = len(next(iter(SeqIO.parse(aln_path, \"fasta\"))).seq)\n",
    "    except StopIteration:\n",
    "        # no alignments found in this file.\n",
    "        raise Exception(\"For some reason, {} contained no alignments.\".format(aln_path))\n",
    "    aligned_seqs = {acc: Seq('-' * l_aln) for acc in union_isolates}  # the aligned strings per isolate.\n",
    "    for record in SeqIO.parse(aln_path, \"fasta\"):\n",
    "        record_acc, contig_idx, _ = record.id.split(\":\")  # third token is assumed to be the gene name (see the cell that runs pgap).\n",
    "        aligned_seqs[record_acc] = record.seq\n",
    "\n",
    "    # compute the distances.\n",
    "    n = len(infant_ordering)\n",
    "    d = np.zeros(shape=(n, n), dtype=int)\n",
    "    for (i, i_idx), (j, j_idx) in itertools.combinations(\n",
    "        infant_ordering.items(),\n",
    "        r=2\n",
    "    ):\n",
    "        i_isolates = infant_groupings[i]\n",
    "        j_isolates = infant_groupings[j]\n",
    "        dist = np.min([hamming(aligned_seqs[x], aligned_seqs[y]) for x, y in itertools.product(i_isolates, j_isolates)])\n",
    "        d[i_idx, j_idx] = dist\n",
    "        d[j_idx, i_idx] = dist\n",
    "    return d\n",
    "\n",
    "\n",
    "def hamming(x: Seq, y: Seq) -> int:\n",
    "    assert len(x) == len(y)\n",
    "    return sum(1 for i, j in zip(x, y) if i != j)\n",
    "\n",
    "\n",
    "# ================================ parse the clustering using the previous set of genes\n",
    "prelim_cluster_df_entries = []\n",
    "# let's open the output of \"efaecalis.ipynb\" notebook from the \"database/complete_recipes\" example.\n",
    "# with open(\"/mnt/e/infant_nt/database/chronostrain_files_with_REFSEQ/efaecalis.clusters_without_isolate_genes.txt\", \"rt\") as f:\n",
    "with open(CHRONOSTRAIN_DB_DIR / \"mlst_virulence_infant_isol.clusters.txt\", \"rt\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        tokens = line.rstrip().split(\"\\t\")\n",
    "        rep = tokens[0]\n",
    "        members = tokens[1].split(\",\")\n",
    "        for member in members:\n",
    "            if member.startswith(\"GCA\"):  # only include isolates\n",
    "                prelim_cluster_df_entries.append({'Accession': member, 'Cluster': rep})\n",
    "\n",
    "prelim_cluster_df = pd.DataFrame(prelim_cluster_df_entries)\n",
    "del prelim_cluster_df_entries\n",
    "    \n",
    "\n",
    "# ================================= go through each cluster one by one and pick gene(s) that splits it.\n",
    "target_gene_set = set()\n",
    "n_clusters = len(pd.unique(prelim_cluster_df['Cluster']))\n",
    "pbar = tqdm(prelim_cluster_df.groupby(\"Cluster\").count().sort_values('Accession', ascending=False).iterrows(), total=n_clusters)\n",
    "for cluster_id, row in pbar:\n",
    "    pbar.set_postfix({\"Cluster\": cluster_id, 'Genes_found': len(target_gene_set)})\n",
    "    section = prelim_cluster_df.loc[prelim_cluster_df['Cluster'] == cluster_id]\n",
    "\n",
    "    infant_groupings = {\n",
    "        infant_id: [\n",
    "            row['Accession']\n",
    "            for _, row in infant_isolate_section.iterrows()\n",
    "        ]\n",
    "        for infant_id, infant_isolate_section in section.merge(infant_isolate_df, on='Accession').groupby(\"Infant\")\n",
    "    }\n",
    "    if len(infant_groupings) < 2:\n",
    "        continue\n",
    "\n",
    "    infant_ordering = {infant_id: idx for idx, infant_id in enumerate(infant_groupings.keys())}\n",
    "    target_genes = get_splitting_genes(infant_groupings, infant_ordering)\n",
    "    target_gene_set = target_gene_set.union(set(target_genes))\n",
    "    # break  # debug; delete to run the whole thing.\n",
    "print(\"Target genes: {}\".format(len(target_gene_set)))\n",
    "\n",
    "# save this to disk.\n",
    "with open(MARKER_SEED_DIR / \"selected_isolate_splitting_genes.txt\", \"wt\") as f:\n",
    "    for g in target_gene_set:\n",
    "        print(g, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc678b-7a46-49b2-abfb-25c310427499",
   "metadata": {},
   "source": [
    "Finally, write these genes to a TSV file for including into the collection of seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45d722fa-7dab-4730-8e58-e4bfa8e2875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to /data/cctm/youn/infant_nt/database/marker_seeds/isolate_annotated_seeds.tsv\n"
     ]
    }
   ],
   "source": [
    "isolate_annotated_tsv = MARKER_SEED_DIR / \"isolate_annotated_seeds.tsv\"\n",
    "with open(isolate_annotated_tsv, \"wt\") as metadata_tsv:\n",
    "    for gene_name in target_gene_set:\n",
    "        if gene_name == \"galE\" or gene_name == \"ssb\":  # these two genes have isolate assemblies with N's inside them. ChronoStrain doesn't handle these gracefully yet, so let's leave them out.\n",
    "            continue\n",
    "        gene_fasta_path = INFANT_ISOLATE_INDEX.parent / 'genes' / f'{gene_name}.fasta'\n",
    "        print(\n",
    "            \"{}\\t{}\\t{}\".format(\n",
    "                gene_name, gene_fasta_path, f\"ISOLATE_ANNOT\"\n",
    "            ), \n",
    "            file=metadata_tsv\n",
    "        )\n",
    "print(f\"Wrote to {isolate_annotated_tsv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4b1d1-f33a-476e-bc11-3d11e596914b",
   "metadata": {},
   "source": [
    "#### 3.5 Combine marker seed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5942cb82-efea-4c0c-99e5-cd601ca98852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Marker seed index: /data/cctm/youn/infant_nt/database/marker_seeds/marker_seed_index.tsv\n"
     ]
    }
   ],
   "source": [
    "!cat \"$MARKER_SEED_DIR\"/mlst_seeds.tsv > $MARKER_SEED_INDEX\n",
    "!cat \"$MARKER_SEED_DIR\"/virulence_seeds.tsv >> $MARKER_SEED_INDEX\n",
    "!cat \"$MARKER_SEED_DIR\"/isolate_annotated_seeds.tsv >> $MARKER_SEED_INDEX\n",
    "\n",
    "print(\"Created Marker seed index: {}\".format(MARKER_SEED_INDEX))\n",
    "assert MARKER_SEED_INDEX.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13da06-b7af-43ad-acf6-820b48e08520",
   "metadata": {},
   "source": [
    "### Step 4: Run Chronostrain's make-db command.\n",
    "\n",
    "By the end of the previous step, we have:\n",
    "\n",
    "1) FASTA files for each gene, listing out seed sequence(s).\n",
    "2) A TSV file (marker_seed_index.tsv) containing a list of gene names and the paths to each of these FASTA files.\n",
    "\n",
    "Using these as inputs, we now construct the database files:\n",
    "1) A JSON file of the strain records and their markers.\n",
    "2) A TXT file of strain records clustered by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63a29b9f-4556-43c0-9aae-501917058d5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p \"$BLAST_DB_DIR\"\n",
    "!env \\\n",
    "    JAX_PLATFORM_NAME=cpu \\\n",
    "    CHRONOSTRAIN_DB_DIR={CHRONOSTRAIN_DB_DIR} \\\n",
    "    CHRONOSTRAIN_LOG_INI={_cwd}/logging.ini \\\n",
    "    chronostrain -c chronostrain.ini \\\n",
    "        make-db \\\n",
    "        -m $MARKER_SEED_INDEX \\\n",
    "        -r $EUROPEAN_ISOLATE_INDEX \\\n",
    "        -r $REFSEQ_INDEX \\\n",
    "        -r $INFANT_ISOLATE_INDEX \\\n",
    "        -b $BLAST_DB_NAME -bd $BLAST_DB_DIR \\\n",
    "        --min-pct-idty $MIN_PCT_IDTY \\\n",
    "        -o $CHRONOSTRAIN_TARGET_JSON \\\n",
    "        --threads $NUM_CORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb366132-063b-4709-8e35-21ca2f0b5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "thresh = 0.998\n",
    "!env \\\n",
    "    JAX_PLATFORM_NAME=cpu \\\n",
    "    CHRONOSTRAIN_DB_DIR={CHRONOSTRAIN_DB_DIR} \\\n",
    "    CHRONOSTRAIN_LOG_INI={_cwd}/logging.ini \\\n",
    "    chronostrain -c chronostrain.ini \\\n",
    "      cluster-db \\\n",
    "      -i $CHRONOSTRAIN_TARGET_JSON \\\n",
    "      -o $CHRONOSTRAIN_TARGET_CLUSTERS \\\n",
    "      --ident-threshold {thresh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659248701839fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "thresh = 0.9999\n",
    "!env \\\n",
    "    JAX_PLATFORM_NAME=cpu \\\n",
    "    CHRONOSTRAIN_DB_DIR={CHRONOSTRAIN_DB_DIR} \\\n",
    "    CHRONOSTRAIN_LOG_INI={_cwd}/logging.ini \\\n",
    "    chronostrain -c chronostrain.ini \\\n",
    "      cluster-db \\\n",
    "      -i $CHRONOSTRAIN_TARGET_JSON \\\n",
    "      -o $CHRONOSTRAIN_TARGET_CLUSTERS_99_99PCT \\\n",
    "      --ident-threshold {thresh}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed936012-425e-4fe2-a414-6a790951dbc2",
   "metadata": {},
   "source": [
    "# OPTIONAL: Compute some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a6eaaa4-e4e8-4311-a22d-0e74888bb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chronostrain.database import JSONParser\n",
    "src_db = JSONParser(\n",
    "    entries_file=CHRONOSTRAIN_TARGET_JSON,\n",
    "    data_dir=CHRONOSTRAIN_DB_DIR,\n",
    "    marker_max_len=50000,\n",
    "    force_refresh=False\n",
    ").parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c7048e4-570d-4be7-9503-08548ba39d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolate_index = pd.read_csv(INFANT_ISOLATE_INDEX, sep='\\t')\n",
    "isolate_ids = set(isolate_index['Accession'])\n",
    "n0 = sum(1 for s in src_db.all_strains() if not s.id in isolate_ids)\n",
    "n1 = sum(1 for s in src_db.all_strains() if s.metadata.genus == 'Enterococcus' and s.metadata.species == 'faecalis' and not s.id.startswith(\"GCA\"))\n",
    "n2 = sum(1 for s in src_db.all_strains() if s.metadata.genus == 'Enterococcus' and s.metadata.species == 'faecalis' and s.id.startswith(\"GCA\"))\n",
    "print(\"# of total entries:\", len(src_db.all_strains()))\n",
    "print(\"# of non-infant isolate entries:\", n0)\n",
    "print(\"# of non-infant isolate E. faecalis entries:\", n1)\n",
    "print(\"# of infant isolate E. faecalis entries:\", n2)\n",
    "\n",
    "\n",
    "marker_lens = np.array([sum(len(m) for m in s.markers) for s in src_db.all_strains()])\n",
    "genome_lens = np.array([s.metadata.total_len for s in src_db.all_strains()])\n",
    "ratios = marker_lens / genome_lens\n",
    "print(\"Database's E. faecalis marker fraction of genome: {} [mean]\".format(np.mean(ratios)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0205f9d-38ea-4bf3-8ef2-3940db05e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entries = []\n",
    "with open(CHRONOSTRAIN_TARGET_CLUSTERS, \"rt\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        tokens = line.rstrip().split(\"\\t\")\n",
    "        rep = tokens[0]\n",
    "        members = tokens[1].split(\",\")\n",
    "        for member in members:\n",
    "            # if member.startswith(\"GCA\"):  # only include isolates\n",
    "            df_entries.append({'Accession': member, 'Cluster': rep})\n",
    "cluster_df = pd.DataFrame(df_entries)\n",
    "del df_entries\n",
    "print(\"# clusters = {}\".format(len(pd.unique(cluster_df['Cluster']))))\n",
    "\n",
    "\n",
    "n_efaecalis = 0\n",
    "for cluster_id in pd.unique(cluster_df['Cluster']):\n",
    "    s = src_db.get_strain(cluster_id)\n",
    "    if s.metadata.genus == 'Enterococcus' and s.metadata.species == 'faecalis':\n",
    "        n_efaecalis += 1\n",
    "print(\"# efaecalis clusters = {}\".format(n_efaecalis))\n",
    "\n",
    "\n",
    "n_infant_clusters = len(pd.unique(cluster_df.loc[cluster_df['Accession'].str.startswith(\"GCA\"), \"Cluster\"]))\n",
    "print(\"# efaecalis clusters with infant isolates = {}\".format(n_infant_clusters))\n",
    "\n",
    "\n",
    "n_infants_per_cluster = []\n",
    "for cluster_id, section in cluster_df.loc[cluster_df['Accession'].str.startswith(\"GCA\")].merge(infant_isolate_df, on='Accession').groupby(\"Cluster\"):\n",
    "    infant_ids = list(pd.unique(section['Infant']))\n",
    "    n_infants_per_cluster.append(len(infant_ids))\n",
    "    # print(cluster_id, \"->\", infant_ids)\n",
    "print(\"# src infants per cluster containing some isolate [min={}, max={}, mean={}, median={}]\".format(\n",
    "    np.min(n_infants_per_cluster),\n",
    "    np.max(n_infants_per_cluster),\n",
    "    np.mean(n_infants_per_cluster),\n",
    "    np.median(n_infants_per_cluster)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b208fa-739f-46d3-97d4-2898f927aca8",
   "metadata": {},
   "source": [
    "# [DEPRECATED CODE BELOW] mSWEEP database (poppunk clustering)\n",
    "\n",
    "To obtain PopPUNK clustering, it was run with the following commands/settings:\n",
    "\n",
    "```\n",
    "poppunk --create-db --output EFaec --r-files input.tsv\n",
    "poppunk --fit-model dbscan --ref-db EFaec --output dbscan\n",
    "poppunk --fit-model refine --ref-db EFaec --model-dir dbscan --output refine --max-a-dist 0.9 --max-pi-dist 0.9\n",
    "```\n",
    "\n",
    "where `input.tsv` is the table of ~2000 european E.faecalis isolates, plus the ~350 infant E.faecalis isolates from ELMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58d0e438-6ea0-46d9-85b3-319f56cf9d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poppunk_clust = pd.read_csv(\"/mnt/e/infant_nt/database/mgems/ref_dir/Efaecalis/ref_clu.tsv\", sep=\"\\t\").rename(columns={\"id\": \"Accession\", \"cluster\": \"Cluster\"})\n",
    "poppunk_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fadf2a78-3b6f-444a-84bb-f0f068331d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# efaecalis clusters = {}\".format(len(pd.unique(poppunk_clust['Cluster']))))\n",
    "\n",
    "\n",
    "n_infant_clusters = len(pd.unique(poppunk_clust.loc[poppunk_clust['Accession'].str.startswith(\"GCA\"), \"Cluster\"]))\n",
    "print(\"# efaecalis clusters with infant isolates = {}\".format(n_infant_clusters))\n",
    "\n",
    "\n",
    "n_infants_per_cluster = []\n",
    "for cluster_id, section in poppunk_clust.loc[poppunk_clust['Accession'].str.startswith(\"GCA\")].merge(infant_isolate_df, on='Accession').groupby(\"Cluster\"):\n",
    "    infant_ids = list(pd.unique(section['Infant']))\n",
    "    n_infants_per_cluster.append(len(infant_ids))\n",
    "    # print(cluster_id, \"->\", infant_ids)\n",
    "\n",
    "print(\"# src infants per cluster containing some isolate [min={}, max={}, mean={}, median={}]\".format(\n",
    "    np.min(n_infants_per_cluster),\n",
    "    np.max(n_infants_per_cluster),\n",
    "    np.mean(n_infants_per_cluster),\n",
    "    np.median(n_infants_per_cluster)\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chronostrain",
   "language": "python",
   "name": "chronostrain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
